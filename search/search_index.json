{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"pandastools: Helper functions for Pandas DataFrames / Series What is it? PandasTools is a Python package that provides additional functions for Pandas DataFrames, Series and Indexes via accessors Main Features TODO Where to get it The source code is currently hosted on GitHub at: https://github.com/phil65/PandasTools The latest released version are available at the Python package index . # or PyPI pip install pandastools Dependencies pandas numba Installation from sources This project uses poetry for dependency management and packaging. Install this first. In the pandastools directory (same one where you found this file after cloning the git repo), execute: poetry install License MIT Documentation The official documentation is hosted on Github Pages: https://phil65.github.io/PandasTools/ Contributing to pandas All contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome. Or maybe through using PandasTools you have an idea of your own or are looking for something in the documentation and thinking \u2018this can be improved\u2019...you can do something about it!","title":"Home"},{"location":"index.html#pandastools-helper-functions-for-pandas-dataframes-series","text":"","title":"pandastools: Helper functions for Pandas DataFrames / Series"},{"location":"index.html#what-is-it","text":"PandasTools is a Python package that provides additional functions for Pandas DataFrames, Series and Indexes via accessors","title":"What is it?"},{"location":"index.html#main-features","text":"TODO","title":"Main Features"},{"location":"index.html#where-to-get-it","text":"The source code is currently hosted on GitHub at: https://github.com/phil65/PandasTools The latest released version are available at the Python package index . # or PyPI pip install pandastools","title":"Where to get it"},{"location":"index.html#dependencies","text":"pandas numba","title":"Dependencies"},{"location":"index.html#installation-from-sources","text":"This project uses poetry for dependency management and packaging. Install this first. In the pandastools directory (same one where you found this file after cloning the git repo), execute: poetry install","title":"Installation from sources"},{"location":"index.html#license","text":"MIT","title":"License"},{"location":"index.html#documentation","text":"The official documentation is hosted on Github Pages: https://phil65.github.io/PandasTools/","title":"Documentation"},{"location":"index.html#contributing-to-pandas","text":"All contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome. Or maybe through using PandasTools you have an idea of your own or are looking for something in the documentation and thinking \u2018this can be improved\u2019...you can do something about it!","title":"Contributing to pandas"},{"location":"changelog.html","text":"v0.5.5 (2022-10-27) Fix bump deps v0.5.4 (2022-04-07) Fix bump deps v0.5.3 (2022-04-06) Fix bump dependencies v0.5.2 (2021-12-27) Fix allow pre-releases for numba v0.5.1 (2021-10-26) Fix dont build for 3.10 v0.5.0 (2021-10-26) Fix get rid of some deprecated stuff Feat add github workflow v0.4.0 (2021-10-26) Feat more flexible add_transition_info v0.3.0 (2020-07-15) Feat DataFrame : add eval method v0.2.3 (2020-06-19) v0.2.2 (2020-06-19) v0.2.1 (2020-06-19) v0.2.0 (2020-06-18) v0.1.1 (2020-06-09) v0.1.0 (2020-06-09) v0.0.8 (2020-06-07)","title":"Changelog"},{"location":"changelog.html#v055-2022-10-27","text":"","title":"v0.5.5 (2022-10-27)"},{"location":"changelog.html#fix","text":"bump deps","title":"Fix"},{"location":"changelog.html#v054-2022-04-07","text":"","title":"v0.5.4 (2022-04-07)"},{"location":"changelog.html#fix_1","text":"bump deps","title":"Fix"},{"location":"changelog.html#v053-2022-04-06","text":"","title":"v0.5.3 (2022-04-06)"},{"location":"changelog.html#fix_2","text":"bump dependencies","title":"Fix"},{"location":"changelog.html#v052-2021-12-27","text":"","title":"v0.5.2 (2021-12-27)"},{"location":"changelog.html#fix_3","text":"allow pre-releases for numba","title":"Fix"},{"location":"changelog.html#v051-2021-10-26","text":"","title":"v0.5.1 (2021-10-26)"},{"location":"changelog.html#fix_4","text":"dont build for 3.10","title":"Fix"},{"location":"changelog.html#v050-2021-10-26","text":"","title":"v0.5.0 (2021-10-26)"},{"location":"changelog.html#fix_5","text":"get rid of some deprecated stuff","title":"Fix"},{"location":"changelog.html#feat","text":"add github workflow","title":"Feat"},{"location":"changelog.html#v040-2021-10-26","text":"","title":"v0.4.0 (2021-10-26)"},{"location":"changelog.html#feat_1","text":"more flexible add_transition_info","title":"Feat"},{"location":"changelog.html#v030-2020-07-15","text":"","title":"v0.3.0 (2020-07-15)"},{"location":"changelog.html#feat_2","text":"DataFrame : add eval method","title":"Feat"},{"location":"changelog.html#v023-2020-06-19","text":"","title":"v0.2.3 (2020-06-19)"},{"location":"changelog.html#v022-2020-06-19","text":"","title":"v0.2.2 (2020-06-19)"},{"location":"changelog.html#v021-2020-06-19","text":"","title":"v0.2.1 (2020-06-19)"},{"location":"changelog.html#v020-2020-06-18","text":"","title":"v0.2.0 (2020-06-18)"},{"location":"changelog.html#v011-2020-06-09","text":"","title":"v0.1.1 (2020-06-09)"},{"location":"changelog.html#v010-2020-06-09","text":"","title":"v0.1.0 (2020-06-09)"},{"location":"changelog.html#v008-2020-06-07","text":"","title":"v0.0.8 (2020-06-07)"},{"location":"contributing.html","text":"Contributing Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions Report Bugs ~~~~~~~~~~~ Report bugs at https://github.com/phil65/pandastools/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs ~~~~~~~~ Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features ~~~~~~~~~~~~~~~~~~ Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation ~~~~~~~~~~~~~~~~~~~ PandasTools could always use more documentation, whether as part of the official PandasTools docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback ~~~~~~~~~~~~~~~ The best way to send feedback is to file an issue at https://github.com/phil65/pandastools/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! Ready to contribute? Here's how to set up pandastools for local development. Fork the pandastools repo on GitHub. Clone your fork locally:: $ git clone git@github.com:your_name_here/pandastools.git Install your local copy into a virtualenv. Assuming you have virtualenvwrapper installed, this is how you set up your fork for local development:: $ mkvirtualenv pandastools $ cd pandastools/ $ python setup.py develop Create a branch for local development:: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass flake8 and the tests: $ flake8 pandastools tests $ py.test To install required development libraries, run \"pip install -r requirements_dev.txt\". Commit your changes and push your branch to GitHub:: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.rst. The pull request should work for Python 3.6 - 3.8. Check https://travis-ci.org/phil65/pandastools/pull_requests and make sure that the tests pass for all supported Python versions.","title":"Contributing"},{"location":"contributing.html#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing.html#types-of-contributions","text":"Report Bugs ~~~~~~~~~~~ Report bugs at https://github.com/phil65/pandastools/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs ~~~~~~~~ Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features ~~~~~~~~~~~~~~~~~~ Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation ~~~~~~~~~~~~~~~~~~~ PandasTools could always use more documentation, whether as part of the official PandasTools docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback ~~~~~~~~~~~~~~~ The best way to send feedback is to file an issue at https://github.com/phil65/pandastools/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Types of Contributions"},{"location":"contributing.html#get-started","text":"Ready to contribute? Here's how to set up pandastools for local development. Fork the pandastools repo on GitHub. Clone your fork locally:: $ git clone git@github.com:your_name_here/pandastools.git Install your local copy into a virtualenv. Assuming you have virtualenvwrapper installed, this is how you set up your fork for local development:: $ mkvirtualenv pandastools $ cd pandastools/ $ python setup.py develop Create a branch for local development:: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass flake8 and the tests: $ flake8 pandastools tests $ py.test To install required development libraries, run \"pip install -r requirements_dev.txt\". Commit your changes and push your branch to GitHub:: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"contributing.html#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.rst. The pull request should work for Python 3.6 - 3.8. Check https://travis-ci.org/phil65/pandastools/pull_requests and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"api/index.html","text":"index module","title":"index"},{"location":"api/index.html#index-module","text":"","title":"index module"},{"location":"api/dataframe.html","text":"dataframe module DataFrameAccessor Source code in pandastools/accessors/dataframe.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 @pd . api . extensions . register_dataframe_accessor ( \"pt\" ) class DataFrameAccessor : def __init__ ( self , parent ): self . _obj = parent def iat ( self , start = None , stop = None , step = 1 ): return self . _obj . iloc [ start : stop : step ] def get_info ( self , show_counts : bool = True ) -> str : \"\"\"Get a concise summary of a DataFrame. This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage. Parameters ---------- show_counts : bool, optional Whether to show the non-null counts. Returns ------- str The summary of a DataFrame. \"\"\" buf = io . StringIO () self . _obj . info ( buf = buf , show_counts = show_counts ) return buf . getvalue () def uniquify_columns ( self ) -> pd . DataFrame : \"\"\"Modify column names of a DataFrame to be unique. In case a DataFrame contains several equal column names, rename all columns except the first one by appending _{count}. Returns ------- pd.DataFrame A DataFrame with unique column names \"\"\" diff = len ( self . _obj . columns ) - len ( set ( self . _obj . columns )) # type: ignore if diff == 0 : return self . _obj seen = set () new = list () for item in self . _obj . columns : # type: ignore fudge = 1 newitem = str ( item ) while newitem in seen : fudge += 1 newitem = f \" { item } _ { fudge } \" seen . add ( newitem ) new . append ( newitem ) df = self . _obj . copy () df . columns = new return df def convert_dtypes ( self , old_type , new_dtype ): cols = self . _obj . select_dtypes ([ old_type ]) . columns df = self . _obj . copy () df [ cols ] = df . select_dtypes ([ old_type ]) . apply ( lambda x : x . astype ( new_dtype )) return df def split ( self , thresh : float , colname : str , extra_rows : int = 0 ) -> pd . DataFrame : \"\"\"Append columns with split information based on supplied criteria. Parameters ---------- thresh : float Threshold to use for splitting. colname : str Column used to detect splits. extra_rows : int, optional Amount of rows to append in both directions for each split section. Returns ------- pd.DataFrame The dataframe including new columns containing the split information. \"\"\" df = self . _obj . drop ( \"secs\" , errors = \"ignore\" , axis = 1 ) array = np . full (( len ( df . index ),), np . nan ) df [ \"process_num\" ] = pd . Categorical ( array ) df = dataimport . add_transition_info ( ds = df , colname = colname , threshold = thresh , extra_rows = extra_rows ) return df def index_to_secs ( self ) -> pd . DataFrame : \"\"\"Convert the DateTimeIndex to seconds, starting with 0. Returns ------- pd.DataFrame DataFrame containing an IntegerIndex \"\"\" if self . _obj . empty : logger . debug ( \"index_to_secs failed. Dataframe empty\" ) return self . _obj elif isinstance ( self . _obj . index , pd . DatetimeIndex ): secs = self . _obj . index . astype ( int ) / 1_000_000_000 df = self . _obj . assign ( secs = secs - secs [ 0 ]) . set_index ( \"secs\" , drop = True ) return df else : logger . debug ( \"index_to_secs failed. No DateTimeIndex\" ) return self . _obj def cleanup ( self ): df = self . _obj . infer_objects () cols = df . select_dtypes ([ \"object\" ]) . columns df [ cols ] = df . select_dtypes ([ \"object\" ]) . apply ( lambda x : x . astype ( \"category\" )) return df def tolerance_bands ( self , window : Union [ int , str ], pct : float ): df = self . _obj rolling = df . rolling ( window = window , center = True , min_periods = 1 ) u_band = np . maximum ( rolling . max (), df * ( pct + 1 )) l_band = np . minimum ( rolling . min (), df * ( 1 - pct )) result = pd . concat ([ df , l_band , u_band ], axis = 1 ) cols = [ f \" { x } _ { y } \" for x in [ \"real\" , \"lower\" , \"upper\" ] for y in df . columns ] result . columns = cols return result def merge_columns ( self , columns : List [ Hashable ], divider : str = \" \" ): def split ( x ): return divider . join ( str ( i ) for i in x ) return self . _obj [ columns ] . apply ( split , axis = 1 ) def duplicate_features ( self , columns : List [ Hashable ]): df = self . _obj new_names = helpers . uniquify_names ( columns , df . columns ) new_cols = df [ columns ] new_cols . columns = new_names df = pd . concat ([ df , new_cols ], axis = 1 ) return df def eval ( self , code : str , variable_name : str = \"df\" ): \"\"\"Apply a script to the dataset.\"\"\" context = { variable_name : self . _obj , \"__builtins__\" : __builtins__ } df = helpers . evaluate ( code = code , context = context , return_val = variable_name ) if not isinstance ( df , pd . DataFrame ): raise TypeError ( \"Function needs to return a dataframe\" ) return df @classmethod def from_script ( cls , code : str , variable_name : str = \"df\" ): \"\"\"Return a ds resulting from a code block. Result is wrapped as function because we dont want \"ds\" hardcoded \"\"\" context = { \"__builtins__\" : __builtins__ } df = helpers . evaluate ( code , context , return_val = variable_name ) if not isinstance ( df , pd . DataFrame ): raise TypeError ( \"Function needs to return a dataframe\" ) return df eval ( code , variable_name = 'df' ) Apply a script to the dataset. Source code in pandastools/accessors/dataframe.py 151 152 153 154 155 156 157 def eval ( self , code : str , variable_name : str = \"df\" ): \"\"\"Apply a script to the dataset.\"\"\" context = { variable_name : self . _obj , \"__builtins__\" : __builtins__ } df = helpers . evaluate ( code = code , context = context , return_val = variable_name ) if not isinstance ( df , pd . DataFrame ): raise TypeError ( \"Function needs to return a dataframe\" ) return df from_script ( code , variable_name = 'df' ) classmethod Return a ds resulting from a code block. Result is wrapped as function because we dont want \"ds\" hardcoded Source code in pandastools/accessors/dataframe.py 159 160 161 162 163 164 165 166 167 168 169 170 @classmethod def from_script ( cls , code : str , variable_name : str = \"df\" ): \"\"\"Return a ds resulting from a code block. Result is wrapped as function because we dont want \"ds\" hardcoded \"\"\" context = { \"__builtins__\" : __builtins__ } df = helpers . evaluate ( code , context , return_val = variable_name ) if not isinstance ( df , pd . DataFrame ): raise TypeError ( \"Function needs to return a dataframe\" ) return df get_info ( show_counts = True ) Get a concise summary of a DataFrame. This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage. Parameters bool, optional Whether to show the non-null counts. Returns str The summary of a DataFrame. Source code in pandastools/accessors/dataframe.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def get_info ( self , show_counts : bool = True ) -> str : \"\"\"Get a concise summary of a DataFrame. This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage. Parameters ---------- show_counts : bool, optional Whether to show the non-null counts. Returns ------- str The summary of a DataFrame. \"\"\" buf = io . StringIO () self . _obj . info ( buf = buf , show_counts = show_counts ) return buf . getvalue () index_to_secs () Convert the DateTimeIndex to seconds, starting with 0. Returns pd.DataFrame DataFrame containing an IntegerIndex Source code in pandastools/accessors/dataframe.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 def index_to_secs ( self ) -> pd . DataFrame : \"\"\"Convert the DateTimeIndex to seconds, starting with 0. Returns ------- pd.DataFrame DataFrame containing an IntegerIndex \"\"\" if self . _obj . empty : logger . debug ( \"index_to_secs failed. Dataframe empty\" ) return self . _obj elif isinstance ( self . _obj . index , pd . DatetimeIndex ): secs = self . _obj . index . astype ( int ) / 1_000_000_000 df = self . _obj . assign ( secs = secs - secs [ 0 ]) . set_index ( \"secs\" , drop = True ) return df else : logger . debug ( \"index_to_secs failed. No DateTimeIndex\" ) return self . _obj split ( thresh , colname , extra_rows = 0 ) Append columns with split information based on supplied criteria. Parameters float Threshold to use for splitting. str Column used to detect splits. int, optional Amount of rows to append in both directions for each split section. Returns pd.DataFrame The dataframe including new columns containing the split information. Source code in pandastools/accessors/dataframe.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 def split ( self , thresh : float , colname : str , extra_rows : int = 0 ) -> pd . DataFrame : \"\"\"Append columns with split information based on supplied criteria. Parameters ---------- thresh : float Threshold to use for splitting. colname : str Column used to detect splits. extra_rows : int, optional Amount of rows to append in both directions for each split section. Returns ------- pd.DataFrame The dataframe including new columns containing the split information. \"\"\" df = self . _obj . drop ( \"secs\" , errors = \"ignore\" , axis = 1 ) array = np . full (( len ( df . index ),), np . nan ) df [ \"process_num\" ] = pd . Categorical ( array ) df = dataimport . add_transition_info ( ds = df , colname = colname , threshold = thresh , extra_rows = extra_rows ) return df uniquify_columns () Modify column names of a DataFrame to be unique. In case a DataFrame contains several equal column names, rename all columns except the first one by appending _{count}. Returns pd.DataFrame A DataFrame with unique column names Source code in pandastools/accessors/dataframe.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def uniquify_columns ( self ) -> pd . DataFrame : \"\"\"Modify column names of a DataFrame to be unique. In case a DataFrame contains several equal column names, rename all columns except the first one by appending _{count}. Returns ------- pd.DataFrame A DataFrame with unique column names \"\"\" diff = len ( self . _obj . columns ) - len ( set ( self . _obj . columns )) # type: ignore if diff == 0 : return self . _obj seen = set () new = list () for item in self . _obj . columns : # type: ignore fudge = 1 newitem = str ( item ) while newitem in seen : fudge += 1 newitem = f \" { item } _ { fudge } \" seen . add ( newitem ) new . append ( newitem ) df = self . _obj . copy () df . columns = new return df","title":"dataframe"},{"location":"api/dataframe.html#dataframe-module","text":"","title":"dataframe module"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor","text":"Source code in pandastools/accessors/dataframe.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 @pd . api . extensions . register_dataframe_accessor ( \"pt\" ) class DataFrameAccessor : def __init__ ( self , parent ): self . _obj = parent def iat ( self , start = None , stop = None , step = 1 ): return self . _obj . iloc [ start : stop : step ] def get_info ( self , show_counts : bool = True ) -> str : \"\"\"Get a concise summary of a DataFrame. This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage. Parameters ---------- show_counts : bool, optional Whether to show the non-null counts. Returns ------- str The summary of a DataFrame. \"\"\" buf = io . StringIO () self . _obj . info ( buf = buf , show_counts = show_counts ) return buf . getvalue () def uniquify_columns ( self ) -> pd . DataFrame : \"\"\"Modify column names of a DataFrame to be unique. In case a DataFrame contains several equal column names, rename all columns except the first one by appending _{count}. Returns ------- pd.DataFrame A DataFrame with unique column names \"\"\" diff = len ( self . _obj . columns ) - len ( set ( self . _obj . columns )) # type: ignore if diff == 0 : return self . _obj seen = set () new = list () for item in self . _obj . columns : # type: ignore fudge = 1 newitem = str ( item ) while newitem in seen : fudge += 1 newitem = f \" { item } _ { fudge } \" seen . add ( newitem ) new . append ( newitem ) df = self . _obj . copy () df . columns = new return df def convert_dtypes ( self , old_type , new_dtype ): cols = self . _obj . select_dtypes ([ old_type ]) . columns df = self . _obj . copy () df [ cols ] = df . select_dtypes ([ old_type ]) . apply ( lambda x : x . astype ( new_dtype )) return df def split ( self , thresh : float , colname : str , extra_rows : int = 0 ) -> pd . DataFrame : \"\"\"Append columns with split information based on supplied criteria. Parameters ---------- thresh : float Threshold to use for splitting. colname : str Column used to detect splits. extra_rows : int, optional Amount of rows to append in both directions for each split section. Returns ------- pd.DataFrame The dataframe including new columns containing the split information. \"\"\" df = self . _obj . drop ( \"secs\" , errors = \"ignore\" , axis = 1 ) array = np . full (( len ( df . index ),), np . nan ) df [ \"process_num\" ] = pd . Categorical ( array ) df = dataimport . add_transition_info ( ds = df , colname = colname , threshold = thresh , extra_rows = extra_rows ) return df def index_to_secs ( self ) -> pd . DataFrame : \"\"\"Convert the DateTimeIndex to seconds, starting with 0. Returns ------- pd.DataFrame DataFrame containing an IntegerIndex \"\"\" if self . _obj . empty : logger . debug ( \"index_to_secs failed. Dataframe empty\" ) return self . _obj elif isinstance ( self . _obj . index , pd . DatetimeIndex ): secs = self . _obj . index . astype ( int ) / 1_000_000_000 df = self . _obj . assign ( secs = secs - secs [ 0 ]) . set_index ( \"secs\" , drop = True ) return df else : logger . debug ( \"index_to_secs failed. No DateTimeIndex\" ) return self . _obj def cleanup ( self ): df = self . _obj . infer_objects () cols = df . select_dtypes ([ \"object\" ]) . columns df [ cols ] = df . select_dtypes ([ \"object\" ]) . apply ( lambda x : x . astype ( \"category\" )) return df def tolerance_bands ( self , window : Union [ int , str ], pct : float ): df = self . _obj rolling = df . rolling ( window = window , center = True , min_periods = 1 ) u_band = np . maximum ( rolling . max (), df * ( pct + 1 )) l_band = np . minimum ( rolling . min (), df * ( 1 - pct )) result = pd . concat ([ df , l_band , u_band ], axis = 1 ) cols = [ f \" { x } _ { y } \" for x in [ \"real\" , \"lower\" , \"upper\" ] for y in df . columns ] result . columns = cols return result def merge_columns ( self , columns : List [ Hashable ], divider : str = \" \" ): def split ( x ): return divider . join ( str ( i ) for i in x ) return self . _obj [ columns ] . apply ( split , axis = 1 ) def duplicate_features ( self , columns : List [ Hashable ]): df = self . _obj new_names = helpers . uniquify_names ( columns , df . columns ) new_cols = df [ columns ] new_cols . columns = new_names df = pd . concat ([ df , new_cols ], axis = 1 ) return df def eval ( self , code : str , variable_name : str = \"df\" ): \"\"\"Apply a script to the dataset.\"\"\" context = { variable_name : self . _obj , \"__builtins__\" : __builtins__ } df = helpers . evaluate ( code = code , context = context , return_val = variable_name ) if not isinstance ( df , pd . DataFrame ): raise TypeError ( \"Function needs to return a dataframe\" ) return df @classmethod def from_script ( cls , code : str , variable_name : str = \"df\" ): \"\"\"Return a ds resulting from a code block. Result is wrapped as function because we dont want \"ds\" hardcoded \"\"\" context = { \"__builtins__\" : __builtins__ } df = helpers . evaluate ( code , context , return_val = variable_name ) if not isinstance ( df , pd . DataFrame ): raise TypeError ( \"Function needs to return a dataframe\" ) return df","title":"DataFrameAccessor"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.eval","text":"Apply a script to the dataset. Source code in pandastools/accessors/dataframe.py 151 152 153 154 155 156 157 def eval ( self , code : str , variable_name : str = \"df\" ): \"\"\"Apply a script to the dataset.\"\"\" context = { variable_name : self . _obj , \"__builtins__\" : __builtins__ } df = helpers . evaluate ( code = code , context = context , return_val = variable_name ) if not isinstance ( df , pd . DataFrame ): raise TypeError ( \"Function needs to return a dataframe\" ) return df","title":"eval()"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.from_script","text":"Return a ds resulting from a code block. Result is wrapped as function because we dont want \"ds\" hardcoded Source code in pandastools/accessors/dataframe.py 159 160 161 162 163 164 165 166 167 168 169 170 @classmethod def from_script ( cls , code : str , variable_name : str = \"df\" ): \"\"\"Return a ds resulting from a code block. Result is wrapped as function because we dont want \"ds\" hardcoded \"\"\" context = { \"__builtins__\" : __builtins__ } df = helpers . evaluate ( code , context , return_val = variable_name ) if not isinstance ( df , pd . DataFrame ): raise TypeError ( \"Function needs to return a dataframe\" ) return df","title":"from_script()"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.get_info","text":"Get a concise summary of a DataFrame. This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage.","title":"get_info()"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.get_info--parameters","text":"bool, optional Whether to show the non-null counts.","title":"Parameters"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.get_info--returns","text":"str The summary of a DataFrame. Source code in pandastools/accessors/dataframe.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def get_info ( self , show_counts : bool = True ) -> str : \"\"\"Get a concise summary of a DataFrame. This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage. Parameters ---------- show_counts : bool, optional Whether to show the non-null counts. Returns ------- str The summary of a DataFrame. \"\"\" buf = io . StringIO () self . _obj . info ( buf = buf , show_counts = show_counts ) return buf . getvalue ()","title":"Returns"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.index_to_secs","text":"Convert the DateTimeIndex to seconds, starting with 0.","title":"index_to_secs()"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.index_to_secs--returns","text":"pd.DataFrame DataFrame containing an IntegerIndex Source code in pandastools/accessors/dataframe.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 def index_to_secs ( self ) -> pd . DataFrame : \"\"\"Convert the DateTimeIndex to seconds, starting with 0. Returns ------- pd.DataFrame DataFrame containing an IntegerIndex \"\"\" if self . _obj . empty : logger . debug ( \"index_to_secs failed. Dataframe empty\" ) return self . _obj elif isinstance ( self . _obj . index , pd . DatetimeIndex ): secs = self . _obj . index . astype ( int ) / 1_000_000_000 df = self . _obj . assign ( secs = secs - secs [ 0 ]) . set_index ( \"secs\" , drop = True ) return df else : logger . debug ( \"index_to_secs failed. No DateTimeIndex\" ) return self . _obj","title":"Returns"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.split","text":"Append columns with split information based on supplied criteria.","title":"split()"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.split--parameters","text":"float Threshold to use for splitting. str Column used to detect splits. int, optional Amount of rows to append in both directions for each split section.","title":"Parameters"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.split--returns","text":"pd.DataFrame The dataframe including new columns containing the split information. Source code in pandastools/accessors/dataframe.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 def split ( self , thresh : float , colname : str , extra_rows : int = 0 ) -> pd . DataFrame : \"\"\"Append columns with split information based on supplied criteria. Parameters ---------- thresh : float Threshold to use for splitting. colname : str Column used to detect splits. extra_rows : int, optional Amount of rows to append in both directions for each split section. Returns ------- pd.DataFrame The dataframe including new columns containing the split information. \"\"\" df = self . _obj . drop ( \"secs\" , errors = \"ignore\" , axis = 1 ) array = np . full (( len ( df . index ),), np . nan ) df [ \"process_num\" ] = pd . Categorical ( array ) df = dataimport . add_transition_info ( ds = df , colname = colname , threshold = thresh , extra_rows = extra_rows ) return df","title":"Returns"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.uniquify_columns","text":"Modify column names of a DataFrame to be unique. In case a DataFrame contains several equal column names, rename all columns except the first one by appending _{count}.","title":"uniquify_columns()"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.uniquify_columns--returns","text":"pd.DataFrame A DataFrame with unique column names Source code in pandastools/accessors/dataframe.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def uniquify_columns ( self ) -> pd . DataFrame : \"\"\"Modify column names of a DataFrame to be unique. In case a DataFrame contains several equal column names, rename all columns except the first one by appending _{count}. Returns ------- pd.DataFrame A DataFrame with unique column names \"\"\" diff = len ( self . _obj . columns ) - len ( set ( self . _obj . columns )) # type: ignore if diff == 0 : return self . _obj seen = set () new = list () for item in self . _obj . columns : # type: ignore fudge = 1 newitem = str ( item ) while newitem in seen : fudge += 1 newitem = f \" { item } _ { fudge } \" seen . add ( newitem ) new . append ( newitem ) df = self . _obj . copy () df . columns = new return df","title":"Returns"},{"location":"api/series.html","text":"series module @author: Philipp Temminghoff","title":"series"},{"location":"api/series.html#series-module","text":"@author: Philipp Temminghoff","title":"series module"}]}