{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"pandastools: Helper functions for Pandas DataFrames / Series","text":""},{"location":"index.html#what-is-it","title":"What is it?","text":"<p>PandasTools is a Python package that provides additional functions for Pandas DataFrames, Series and Indexes via accessors</p>"},{"location":"index.html#main-features","title":"Main Features","text":"<ul> <li>TODO</li> </ul>"},{"location":"index.html#where-to-get-it","title":"Where to get it","text":"<p>The source code is currently hosted on GitHub at: https://github.com/phil65/PandasTools</p> <p>The latest released version are available at the Python package index.</p> <pre><code># or PyPI\npip install pandastools\n</code></pre>"},{"location":"index.html#dependencies","title":"Dependencies","text":"<ul> <li>pandas</li> </ul>"},{"location":"index.html#installation-from-sources","title":"Installation from sources","text":"<p>This project uses poetry for dependency management and packaging. Install this first. In the <code>pandastools</code> directory (same one where you found this file after cloning the git repo), execute:</p> <pre><code>poetry install\n</code></pre>"},{"location":"index.html#license","title":"License","text":"<p>MIT</p>"},{"location":"index.html#documentation","title":"Documentation","text":"<p>The official documentation is hosted on Github Pages: https://phil65.github.io/PandasTools/</p>"},{"location":"index.html#contributing-to-pandas","title":"Contributing to pandas","text":"<p>All contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome.</p> <p>Or maybe through using PandasTools you have an idea of your own or are looking for something in the documentation and thinking \u2018this can be improved\u2019...you can do something about it!</p>"},{"location":"changelog.html","title":"Changelog","text":""},{"location":"changelog.html#v062-2023-02-03","title":"v0.6.2 (2023-02-03)","text":""},{"location":"changelog.html#fix","title":"Fix","text":"<ul> <li>include python 3.11 in dependencies</li> </ul>"},{"location":"changelog.html#v061-2023-02-03","title":"v0.6.1 (2023-02-03)","text":""},{"location":"changelog.html#fix_1","title":"Fix","text":"<ul> <li>make threshold param for add_transition_info mandatory</li> </ul>"},{"location":"changelog.html#v060-2022-11-11","title":"v0.6.0 (2022-11-11)","text":""},{"location":"changelog.html#feat","title":"Feat","text":"<ul> <li>add dtypes module</li> </ul>"},{"location":"changelog.html#v056-2022-11-02","title":"v0.5.6 (2022-11-02)","text":""},{"location":"changelog.html#fix_2","title":"Fix","text":"<ul> <li>pyupgrade stuff</li> </ul>"},{"location":"changelog.html#v055-2022-10-27","title":"v0.5.5 (2022-10-27)","text":""},{"location":"changelog.html#fix_3","title":"Fix","text":"<ul> <li>bump deps</li> </ul>"},{"location":"changelog.html#v054-2022-04-07","title":"v0.5.4 (2022-04-07)","text":""},{"location":"changelog.html#fix_4","title":"Fix","text":"<ul> <li>bump deps</li> </ul>"},{"location":"changelog.html#v053-2022-04-06","title":"v0.5.3 (2022-04-06)","text":""},{"location":"changelog.html#fix_5","title":"Fix","text":"<ul> <li>bump dependencies</li> </ul>"},{"location":"changelog.html#v052-2021-12-27","title":"v0.5.2 (2021-12-27)","text":""},{"location":"changelog.html#fix_6","title":"Fix","text":"<ul> <li>allow pre-releases for numba</li> </ul>"},{"location":"changelog.html#v051-2021-10-26","title":"v0.5.1 (2021-10-26)","text":""},{"location":"changelog.html#fix_7","title":"Fix","text":"<ul> <li>dont build for 3.10</li> </ul>"},{"location":"changelog.html#v050-2021-10-26","title":"v0.5.0 (2021-10-26)","text":""},{"location":"changelog.html#fix_8","title":"Fix","text":"<ul> <li>get rid of some deprecated stuff</li> </ul>"},{"location":"changelog.html#feat_1","title":"Feat","text":"<ul> <li>add github workflow</li> </ul>"},{"location":"changelog.html#v040-2021-10-26","title":"v0.4.0 (2021-10-26)","text":""},{"location":"changelog.html#feat_2","title":"Feat","text":"<ul> <li>more flexible add_transition_info</li> </ul>"},{"location":"changelog.html#v030-2020-07-15","title":"v0.3.0 (2020-07-15)","text":""},{"location":"changelog.html#feat_3","title":"Feat","text":"<ul> <li>DataFrame: add eval method</li> </ul>"},{"location":"changelog.html#v023-2020-06-19","title":"v0.2.3 (2020-06-19)","text":""},{"location":"changelog.html#v022-2020-06-19","title":"v0.2.2 (2020-06-19)","text":""},{"location":"changelog.html#v021-2020-06-19","title":"v0.2.1 (2020-06-19)","text":""},{"location":"changelog.html#v020-2020-06-18","title":"v0.2.0 (2020-06-18)","text":""},{"location":"changelog.html#v011-2020-06-09","title":"v0.1.1 (2020-06-09)","text":""},{"location":"changelog.html#v010-2020-06-09","title":"v0.1.0 (2020-06-09)","text":""},{"location":"changelog.html#v008-2020-06-07","title":"v0.0.8 (2020-06-07)","text":""},{"location":"contributing.html","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing.html#types-of-contributions","title":"Types of Contributions","text":"<p>Report Bugs ~~~~~~~~~~~</p> <p>Report bugs at https://github.com/phil65/pandastools/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul> <p>Fix Bugs ~~~~~~~~</p> <p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.</p> <p>Implement Features ~~~~~~~~~~~~~~~~~~</p> <p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p> <p>Write Documentation ~~~~~~~~~~~~~~~~~~~</p> <p>PandasTools could always use more documentation, whether as part of the official PandasTools docs, in docstrings, or even on the web in blog posts, articles, and such.</p> <p>Submit Feedback ~~~~~~~~~~~~~~~</p> <p>The best way to send feedback is to file an issue at https://github.com/phil65/pandastools/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions   are welcome :)</li> </ul>"},{"location":"contributing.html#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up <code>pandastools</code> for local development.</p> <ol> <li>Fork the <code>pandastools</code> repo on GitHub.</li> <li> <p>Clone your fork locally::</p> <p>$ git clone git@github.com:your_name_here/pandastools.git</p> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have virtualenvwrapper installed, this is how you set up your fork for local development::</p> <p>$ mkvirtualenv pandastools $ cd pandastools/ $ python setup.py develop</p> </li> <li> <p>Create a branch for local development::</p> <p>$ git checkout -b name-of-your-bugfix-or-feature</p> </li> </ol> <p>Now you can make your changes locally.</p> <ol> <li> <p>When you're done making changes, check that your changes pass flake8 and the    tests:</p> <p>$ flake8 pandastools tests $ py.test</p> </li> </ol> <p>To install required development libraries, run \"pip install -r requirements_dev.txt\".</p> <ol> <li> <p>Commit your changes and push your branch to GitHub::</p> <p>$ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature</p> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing.html#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated. Put    your new functionality into a function with a docstring, and add the    feature to the list in README.rst.</li> <li>The pull request should work for Python 3.6 - 3.8. Check    https://travis-ci.org/phil65/pandastools/pull_requests    and make sure that the tests pass for all supported Python versions.</li> </ol>"},{"location":"api/index.html","title":"index module","text":""},{"location":"api/dataframe.html","title":"dataframe module","text":""},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor","title":"<code>DataFrameAccessor</code>","text":"Source code in <code>pandastools/accessors/dataframe.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"pt\")\nclass DataFrameAccessor:\n    def __init__(self, parent):\n        self._obj = parent\n\n    def iat(self, start=None, stop=None, step=1):\n        return self._obj.iloc[start:stop:step]\n\n    def get_info(self, show_counts: bool = True) -&gt; str:\n\"\"\"Get a concise summary of a DataFrame.\n\n        This method prints information about a DataFrame including\n        the index dtype and column dtypes, non-null values and memory usage.\n\n        Parameters\n        ----------\n        show_counts : bool, optional\n            Whether to show the non-null counts.\n\n        Returns\n        -------\n        str\n            The summary of a DataFrame.\n        \"\"\"\n        buf = io.StringIO()\n        self._obj.info(buf=buf, show_counts=show_counts)\n        return buf.getvalue()\n\n    def uniquify_columns(self) -&gt; pd.DataFrame:\n\"\"\"Modify column names of a DataFrame to be unique.\n\n        In case a DataFrame contains several equal column names, rename all columns\n        except the first one by appending _{count}.\n\n        Returns\n        -------\n        pd.DataFrame\n            A DataFrame with unique column names\n        \"\"\"\n        diff = len(self._obj.columns) - len(set(self._obj.columns))  # type: ignore\n        if diff == 0:\n            return self._obj\n        seen = set()\n        new = list()\n        for item in self._obj.columns:  # type: ignore\n            fudge = 1\n            newitem = str(item)\n            while newitem in seen:\n                fudge += 1\n                newitem = f\"{item}_{fudge}\"\n            seen.add(newitem)\n            new.append(newitem)\n        df = self._obj.copy()\n        df.columns = new\n        return df\n\n    def convert_dtypes(self, old_type, new_dtype):\n        cols = self._obj.select_dtypes([old_type]).columns\n        df = self._obj.copy()\n        df[cols] = df.select_dtypes([old_type]).apply(lambda x: x.astype(new_dtype))\n        return df\n\n    def split(self, thresh: float, colname: str, extra_rows: int = 0) -&gt; pd.DataFrame:\n\"\"\"Append columns with split information based on supplied criteria.\n\n        Parameters\n        ----------\n        thresh : float\n            Threshold to use for splitting.\n        colname : str\n            Column used to detect splits.\n        extra_rows : int, optional\n            Amount of rows to append in both directions for each split section.\n\n        Returns\n        -------\n        pd.DataFrame\n            The dataframe including new columns containing the split information.\n        \"\"\"\n        df = self._obj.drop(\"secs\", errors=\"ignore\", axis=1)\n        array = np.full((len(df.index),), np.nan)\n        df[\"process_num\"] = pd.Categorical(array)\n        df = dataimport.add_transition_info(\n            ds=df, colname=colname, threshold=thresh, extra_rows=extra_rows\n        )\n        return df\n\n    def index_to_secs(self) -&gt; pd.DataFrame:\n\"\"\"Convert the DateTimeIndex to seconds, starting with 0.\n\n        Returns\n        -------\n        pd.DataFrame\n            DataFrame containing an IntegerIndex\n        \"\"\"\n        if self._obj.empty:\n            logger.debug(\"index_to_secs failed. Dataframe empty\")\n            return self._obj\n        elif isinstance(self._obj.index, pd.DatetimeIndex):\n            secs = self._obj.index.astype(int) / 1_000_000_000\n            df = self._obj.assign(secs=secs - secs[0]).set_index(\"secs\", drop=True)\n            return df\n        else:\n            logger.debug(\"index_to_secs failed. No DateTimeIndex\")\n            return self._obj\n\n    def cleanup(self):\n        df = self._obj.infer_objects()\n        cols = df.select_dtypes([\"object\"]).columns\n        df[cols] = df.select_dtypes([\"object\"]).apply(lambda x: x.astype(\"category\"))\n        return df\n\n    def tolerance_bands(self, window: int | str, pct: float):\n        df = self._obj\n        rolling = df.rolling(window=window, center=True, min_periods=1)\n        u_band = np.maximum(rolling.max(), df * (pct + 1))\n        l_band = np.minimum(rolling.min(), df * (1 - pct))\n        result = pd.concat([df, l_band, u_band], axis=1)\n        cols = [f\"{x}_{y}\" for x in [\"real\", \"lower\", \"upper\"] for y in df.columns]\n        result.set_axis(cols, axis=\"columns\")\n        return result\n\n    def merge_columns(self, columns: list[Hashable], divider: str = \" \"):\n        def split(x):\n            return divider.join(str(i) for i in x)\n\n        return self._obj[columns].apply(split, axis=1)\n\n    def duplicate_features(self, columns: list[Hashable]):\n        df = self._obj\n        new_names = helpers.uniquify_names(columns, df.columns)\n        new_cols = df[columns]\n        new_cols.columns = new_names\n        df = pd.concat([df, new_cols], axis=1)\n        return df\n\n    def eval(self, code: str, variable_name: str = \"df\"):\n\"\"\"Apply a script to the dataset.\"\"\"\n        context = {variable_name: self._obj, \"__builtins__\": __builtins__}\n        df = helpers.evaluate(code=code, context=context, return_val=variable_name)\n        if not isinstance(df, pd.DataFrame):\n            raise TypeError(\"Function needs to return a dataframe\")\n        return df\n\n    @classmethod\n    def from_script(cls, code: str, variable_name: str = \"df\"):\n\"\"\"Return a ds resulting from a code block.\n\n        Result is wrapped as function\n        because we dont want \"ds\" hardcoded\n        \"\"\"\n        context = {\"__builtins__\": __builtins__}\n        df = helpers.evaluate(code, context, return_val=variable_name)\n        if not isinstance(df, pd.DataFrame):\n            raise TypeError(\"Function needs to return a dataframe\")\n        return df\n</code></pre>"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.eval","title":"<code>eval(code, variable_name='df')</code>","text":"<p>Apply a script to the dataset.</p> Source code in <code>pandastools/accessors/dataframe.py</code> <pre><code>def eval(self, code: str, variable_name: str = \"df\"):\n\"\"\"Apply a script to the dataset.\"\"\"\n    context = {variable_name: self._obj, \"__builtins__\": __builtins__}\n    df = helpers.evaluate(code=code, context=context, return_val=variable_name)\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"Function needs to return a dataframe\")\n    return df\n</code></pre>"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.from_script","title":"<code>from_script(code, variable_name='df')</code>  <code>classmethod</code>","text":"<p>Return a ds resulting from a code block.</p> <p>Result is wrapped as function because we dont want \"ds\" hardcoded</p> Source code in <code>pandastools/accessors/dataframe.py</code> <pre><code>@classmethod\ndef from_script(cls, code: str, variable_name: str = \"df\"):\n\"\"\"Return a ds resulting from a code block.\n\n    Result is wrapped as function\n    because we dont want \"ds\" hardcoded\n    \"\"\"\n    context = {\"__builtins__\": __builtins__}\n    df = helpers.evaluate(code, context, return_val=variable_name)\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"Function needs to return a dataframe\")\n    return df\n</code></pre>"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.get_info","title":"<code>get_info(show_counts=True)</code>","text":"<p>Get a concise summary of a DataFrame.</p> <p>This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage.</p>"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.get_info--parameters","title":"Parameters","text":"bool, optional <p>Whether to show the non-null counts.</p>"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.get_info--returns","title":"Returns","text":"<p>str     The summary of a DataFrame.</p> Source code in <code>pandastools/accessors/dataframe.py</code> <pre><code>def get_info(self, show_counts: bool = True) -&gt; str:\n\"\"\"Get a concise summary of a DataFrame.\n\n    This method prints information about a DataFrame including\n    the index dtype and column dtypes, non-null values and memory usage.\n\n    Parameters\n    ----------\n    show_counts : bool, optional\n        Whether to show the non-null counts.\n\n    Returns\n    -------\n    str\n        The summary of a DataFrame.\n    \"\"\"\n    buf = io.StringIO()\n    self._obj.info(buf=buf, show_counts=show_counts)\n    return buf.getvalue()\n</code></pre>"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.index_to_secs","title":"<code>index_to_secs()</code>","text":"<p>Convert the DateTimeIndex to seconds, starting with 0.</p>"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.index_to_secs--returns","title":"Returns","text":"<p>pd.DataFrame     DataFrame containing an IntegerIndex</p> Source code in <code>pandastools/accessors/dataframe.py</code> <pre><code>def index_to_secs(self) -&gt; pd.DataFrame:\n\"\"\"Convert the DateTimeIndex to seconds, starting with 0.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame containing an IntegerIndex\n    \"\"\"\n    if self._obj.empty:\n        logger.debug(\"index_to_secs failed. Dataframe empty\")\n        return self._obj\n    elif isinstance(self._obj.index, pd.DatetimeIndex):\n        secs = self._obj.index.astype(int) / 1_000_000_000\n        df = self._obj.assign(secs=secs - secs[0]).set_index(\"secs\", drop=True)\n        return df\n    else:\n        logger.debug(\"index_to_secs failed. No DateTimeIndex\")\n        return self._obj\n</code></pre>"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.split","title":"<code>split(thresh, colname, extra_rows=0)</code>","text":"<p>Append columns with split information based on supplied criteria.</p>"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.split--parameters","title":"Parameters","text":"float <p>Threshold to use for splitting.</p> str <p>Column used to detect splits.</p> int, optional <p>Amount of rows to append in both directions for each split section.</p>"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.split--returns","title":"Returns","text":"<p>pd.DataFrame     The dataframe including new columns containing the split information.</p> Source code in <code>pandastools/accessors/dataframe.py</code> <pre><code>def split(self, thresh: float, colname: str, extra_rows: int = 0) -&gt; pd.DataFrame:\n\"\"\"Append columns with split information based on supplied criteria.\n\n    Parameters\n    ----------\n    thresh : float\n        Threshold to use for splitting.\n    colname : str\n        Column used to detect splits.\n    extra_rows : int, optional\n        Amount of rows to append in both directions for each split section.\n\n    Returns\n    -------\n    pd.DataFrame\n        The dataframe including new columns containing the split information.\n    \"\"\"\n    df = self._obj.drop(\"secs\", errors=\"ignore\", axis=1)\n    array = np.full((len(df.index),), np.nan)\n    df[\"process_num\"] = pd.Categorical(array)\n    df = dataimport.add_transition_info(\n        ds=df, colname=colname, threshold=thresh, extra_rows=extra_rows\n    )\n    return df\n</code></pre>"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.uniquify_columns","title":"<code>uniquify_columns()</code>","text":"<p>Modify column names of a DataFrame to be unique.</p> <p>In case a DataFrame contains several equal column names, rename all columns except the first one by appending _{count}.</p>"},{"location":"api/dataframe.html#pandastools.accessors.dataframe.DataFrameAccessor.uniquify_columns--returns","title":"Returns","text":"<p>pd.DataFrame     A DataFrame with unique column names</p> Source code in <code>pandastools/accessors/dataframe.py</code> <pre><code>def uniquify_columns(self) -&gt; pd.DataFrame:\n\"\"\"Modify column names of a DataFrame to be unique.\n\n    In case a DataFrame contains several equal column names, rename all columns\n    except the first one by appending _{count}.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame with unique column names\n    \"\"\"\n    diff = len(self._obj.columns) - len(set(self._obj.columns))  # type: ignore\n    if diff == 0:\n        return self._obj\n    seen = set()\n    new = list()\n    for item in self._obj.columns:  # type: ignore\n        fudge = 1\n        newitem = str(item)\n        while newitem in seen:\n            fudge += 1\n            newitem = f\"{item}_{fudge}\"\n        seen.add(newitem)\n        new.append(newitem)\n    df = self._obj.copy()\n    df.columns = new\n    return df\n</code></pre>"},{"location":"api/series.html","title":"series module","text":""}]}